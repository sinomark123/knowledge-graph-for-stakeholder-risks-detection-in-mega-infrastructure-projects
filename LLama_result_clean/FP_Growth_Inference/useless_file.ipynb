{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option2=\"\"\"Based on the given sentence, I have identified the following risks and their types:\n",
    "Risks:\n",
    "Risk 1: Landslide risk (geological risk)\n",
    "Risk Type: Seismic hazard risk\n",
    "Risk 2: Seismic risk (geological risk)\n",
    "Risk Type: Earthquake risk\n",
    "Risk 3: Structural risk (engineering risk)\n",
    "Risk Type: Failure of non-structural components risk\n",
    "\n",
    "Please note that these are my interpretations based on the given sentence, and there may be other potential risks and risk types that could be identified with further analysis.\"\"\"\n",
    "\n",
    "option3=\"\"\"  Of course! I'd be happy to help you identify and summarize the risks in the given sentence.\n",
    "Risks:\n",
    "* Terrorist attack\n",
    "* Structural stability\n",
    "* Accessibility to terrorists\n",
    "* Resistance to specific threat\n",
    "\n",
    "Risk Type:\n",
    "\n",
    "I have identified four types of risks in the sentence:\n",
    "1. Terrorist attack: This risk refers to the potential threat of a terrorist attack on the bridge, which could cause significant damage and disrupt the functioning of the bridge.\n",
    "2. Structural stability: This risk refers to the potential failure of the bridge's structural components, which could lead to a collapse of the bridge and cause harm to people and structures.\n",
    "3. Accessibility to terrorists: This risk refers to the ease with which terrorists could access the bridge and carry out a attack.\n",
    "4. Resistance to specific threat: This risk refers to the ability of the bridge's components to withstand a specific type of threat, such as a bomb or a missile attack.\n",
    "I hope this helps! Let me know if you have any further questions.\n",
    "\n",
    "\"\"\"\n",
    "test.append(option2)\n",
    "test.append(option3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run each_answer.py\n",
    "sample1=[]\n",
    "\n",
    "for val in test:\n",
    "    proclass=Answer(val)\n",
    "    result=proclass.parse()\n",
    "    sample1.append(result)\n",
    "    print(result)\n",
    "# pattern = r\"[^a-zA-Z\\s,';-]+\"\n",
    "# for val in sample1[-2]:\n",
    "#     matches = re.split(pattern, val)\n",
    "#     print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run each_answer.py\n",
    "for index, nounce in enumerate(test):\n",
    "    # if index == 4:\n",
    "    jack = ShortSentenceCut(nounce)\n",
    "    risk_set : List[str] = jack.input_structure()\n",
    "    print(risk_set)\n",
    "\n",
    "%run each_answer.py\n",
    "jack = ShortSentenceCut(test[3])\n",
    "valid, value = jack.format_tracking()\n",
    "print(valid, \"\\n\\n\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run each_answer.py\n",
    "read_content=\"\"\n",
    "for val in [\"output/output.txt\", \"output/output1.txt\", \"output/output2.txt\", \"output/output3.txt\"]:\n",
    "    with open(val, \"r\") as file:\n",
    "        read_content+=file.read()\n",
    "\n",
    "all = read_content.split(\"\\n\\n\\n\")\n",
    "%run each_answer.py\n",
    "success = []\n",
    "\n",
    "for index, nounce in enumerate(all[:100]):\n",
    "    try:\n",
    "        jack = ShortSentenceCut(nounce)\n",
    "        risk_set : List[str] = jack.two_group()\n",
    "        success.append(risk_set)\n",
    "    except Exception as exp:\n",
    "        print(index, \"\\n\", exp)\n",
    "\n",
    "# Function to update values in the \"types\" and \"risk\" columns based on the condition\n",
    "def update_types_risk(row):\n",
    "    if not isinstance(row['types'], str):\n",
    "        return row[\"types\"], row[\"risk\"]\n",
    "\n",
    "    if row['types'].endswith(\"risk\"):\n",
    "        return row['risk'], row['types']\n",
    "    else:\n",
    "        return row['types'], row['risk']\n",
    "\n",
    "# Apply the function to update the \"types\" and \"risk\" columns\n",
    "val['types'], val['risk'] = zip(*val.apply(update_types_risk, axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is for Java FP-Growth expanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "schema = StructType([\n",
    "    StructField(\"items\", ArrayType(StringType()), nullable=True)\n",
    "])\n",
    "A = [\n",
    "    [\"r\", \"z\", \"h\", \"k\", \"p\"],\n",
    "    [\"z\", \"y\", \"x\", \"w\", \"v\"],\n",
    "    [\"s\", \"x\", \"o\", \"n\", \"r\"],\n",
    "    [\"x\", \"z\", \"y\", \"m\", \"t\"],\n",
    "    [\"z\"],\n",
    "    [\"x\", \"z\", \"y\", \"r\", \"q\"]\n",
    "]\n",
    "rdd = spark.sparkContext.parallelize(sets_proper)\n",
    "df = spark.createDataFrame(rdd.map(lambda x: (x,)), schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(truncate=False)\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "fp = FPGrowth(itemsCol=\"items\", minSupport=0.000107, minConfidence=0.1)\n",
    "fpm=fp.fit(df)\n",
    "fpm.setPredictionCol(\"newPrediction\")\n",
    "# fpm.freqItemsets.sort(\"items\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "fp_association = fpm.associationRules.withColumn('antecedent', F.concat_ws('-', F.col(\"antecedent\").cast(\"array<string>\")))\\\n",
    "                         .withColumn('consequent', F.concat_ws('-', F.col(\"consequent\").cast(\"array<string>\")))\n",
    "new_data = spark.createDataFrame([([\"t\", \"s\"], )], [\"items\"])\n",
    "fp_association.write.csv(r\"../FP_Growth_Inference/fpres.csv\", mode = \"overwrite\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Approach on Large Matrix Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namedEntityUpper = cos_sim(data, data[:int(len(data)/20)])\n",
    "namedEntityUpper.shape\n",
    "mask = torch.gt(namedEntityUpper, 0.85)\n",
    "soCalled = namedEntityUpper * mask  # namedEntityUpper.cpu() * mask.cpu()\n",
    "soCalled.shape\n",
    "soCalled = namedEntityUpper.cpu()[mask.cpu()]\n",
    "indices = torch.nonzero(mask, as_tuple=False)\n",
    "indices.shape\n",
    "pureIdx = indices.numpy()\n",
    "conMask = pureIdx[:,0]!=pureIdx[:,1]\n",
    "pureIdx = pureIdx[conMask]\n",
    "pureIdx.shape\n",
    "keys = np.unique(pureIdx[:,0])\n",
    "clusters = {}\n",
    "for key in keys:\n",
    "    cluster = pureIdx[pureIdx[:,0]==key][:,1]\n",
    "    fetch = df.iloc[:,0].values[cluster].tolist()\n",
    "    clusters[key] = fetch"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
