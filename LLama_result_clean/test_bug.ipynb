{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset,threshold):\n",
    "    col_corr=dict() # set will contains unique values.drop=set()corr_matrix=dataset.corr() #finding the correlation between columns.\n",
    "    drop=set()\n",
    "    corr_matrix=dataset.corr() #finding the correlation between columns.\n",
    "    flag=True\n",
    "    for i in range(len(corr_matrix.columns)): #number of columnsfor j in range(i):if abs(corr_matrix.iloc[i,j])>threshold: #checking the correlation between columns.flag=False\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j])>threshold:\n",
    "                flag=False\n",
    "                if (corr_matrix.columns[j] not in col_corr.keys()):\n",
    "                    col_corr[corr_matrix.columns[i]]=corr_matrix.columns[j]\n",
    "                    drop.add(corr_matrix.columns[j])\n",
    "                    drop.add(corr_matrix.columns[i])\n",
    "                    return col_corr, drop,flag #returning set of column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "def combine(correlated_col:dict, drop:set):\n",
    "    pca=PCA(n_components=1)\n",
    "    global i\n",
    "    for key in correlated_col.keys():\n",
    "        print(key)\n",
    "        X=data[[key,correlated_col[key]]]\n",
    "        print(X)\n",
    "        pca.fit(X)\n",
    "        data[\"cf\"+str(i)]=pca.transform(X)\n",
    "        i+=1\n",
    "    for item in drop:\n",
    "        data.drop(item,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative(df, threshold) :\n",
    "    stop=False\n",
    "    while(stop==False):\n",
    "        print(\"hi\")\n",
    "        sns.heatmap(data.corr())\n",
    "        correlated_col, drop, stop=correlation(df,threshold)\n",
    "        combine(correlated_col, drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import *\n",
    "\n",
    "filelist: List[pd.DataFrame] = []\n",
    "for filenum in [\"wuhu\" + str(val) + \".csv\" for val in range(4)]:\n",
    "    file = pd.read_csv(filenum)\n",
    "    filelist.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "riskname = pd.concat(filelist, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "riskname: List[str] = riskname.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1582\n"
     ]
    }
   ],
   "source": [
    "collector = set()\n",
    "unique: List[str] = []\n",
    "\n",
    "for ele in riskname:\n",
    "    lowerele = ele[0].lower()\n",
    "    if lowerele not in collector:\n",
    "        collector.add(lowerele)\n",
    "        unique.append(ele[0])\n",
    "    \n",
    "print(len(unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(unique, columns=[\"risk\"]).to_csv(\"new_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_success=success.copy()\n",
    "\n",
    "my_res, blyat = set(), list()\n",
    "for index, sub_list in enumerate(success):\n",
    "    if not sub_list: continue\n",
    "    sub_list = [ele.replace(\")\", \"\").strip() for ele in sub_list if len(ele.split(\" \"))<8]\n",
    "    if sub_list: blyat.append((index, sub_list))\n",
    "\n",
    "    # my_res.update(sub_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for order_ele in abs_data[:10]:\n",
    "    normal, extra, index = order_ele\n",
    "    normal[\"idx\"] = index\n",
    "    normal = {key: ' '.join(value) if isinstance(value, list) else str(value) for key, value in data.items()}\n",
    "    extra_dict: Dict[str, str] = {obj[0]: obj[1] for obj in extra}\n",
    "    extra_dict[\"idx\"] = index\n",
    "    df_normal, df_extra = pd.DataFrame(normal), pd.DataFrame(extra_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
