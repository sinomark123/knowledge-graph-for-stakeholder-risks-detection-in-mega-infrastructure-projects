{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option2=\"\"\"Based on the given sentence, I have identified the following risks and their types:\n",
    "Risks:\n",
    "Risk 1: Landslide risk (geological risk)\n",
    "Risk Type: Seismic hazard risk\n",
    "Risk 2: Seismic risk (geological risk)\n",
    "Risk Type: Earthquake risk\n",
    "Risk 3: Structural risk (engineering risk)\n",
    "Risk Type: Failure of non-structural components risk\n",
    "\n",
    "Please note that these are my interpretations based on the given sentence, and there may be other potential risks and risk types that could be identified with further analysis.\"\"\"\n",
    "\n",
    "option3=\"\"\"  Of course! I'd be happy to help you identify and summarize the risks in the given sentence.\n",
    "Risks:\n",
    "* Terrorist attack\n",
    "* Structural stability\n",
    "* Accessibility to terrorists\n",
    "* Resistance to specific threat\n",
    "\n",
    "Risk Type:\n",
    "\n",
    "I have identified four types of risks in the sentence:\n",
    "1. Terrorist attack: This risk refers to the potential threat of a terrorist attack on the bridge, which could cause significant damage and disrupt the functioning of the bridge.\n",
    "2. Structural stability: This risk refers to the potential failure of the bridge's structural components, which could lead to a collapse of the bridge and cause harm to people and structures.\n",
    "3. Accessibility to terrorists: This risk refers to the ease with which terrorists could access the bridge and carry out a attack.\n",
    "4. Resistance to specific threat: This risk refers to the ability of the bridge's components to withstand a specific type of threat, such as a bomb or a missile attack.\n",
    "I hope this helps! Let me know if you have any further questions.\n",
    "\n",
    "\"\"\"\n",
    "test.append(option2)\n",
    "test.append(option3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run each_answer.py\n",
    "sample1=[]\n",
    "\n",
    "for val in test:\n",
    "    proclass=Answer(val)\n",
    "    result=proclass.parse()\n",
    "    sample1.append(result)\n",
    "    print(result)\n",
    "# pattern = r\"[^a-zA-Z\\s,';-]+\"\n",
    "# for val in sample1[-2]:\n",
    "#     matches = re.split(pattern, val)\n",
    "#     print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run each_answer.py\n",
    "for index, nounce in enumerate(test):\n",
    "    # if index == 4:\n",
    "    jack = ShortSentenceCut(nounce)\n",
    "    risk_set : List[str] = jack.input_structure()\n",
    "    print(risk_set)\n",
    "\n",
    "%run each_answer.py\n",
    "jack = ShortSentenceCut(test[3])\n",
    "valid, value = jack.format_tracking()\n",
    "print(valid, \"\\n\\n\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run each_answer.py\n",
    "read_content=\"\"\n",
    "for val in [\"output/output.txt\", \"output/output1.txt\", \"output/output2.txt\", \"output/output3.txt\"]:\n",
    "    with open(val, \"r\") as file:\n",
    "        read_content+=file.read()\n",
    "\n",
    "all = read_content.split(\"\\n\\n\\n\")\n",
    "%run each_answer.py\n",
    "success = []\n",
    "\n",
    "for index, nounce in enumerate(all[:100]):\n",
    "    try:\n",
    "        jack = ShortSentenceCut(nounce)\n",
    "        risk_set : List[str] = jack.two_group()\n",
    "        success.append(risk_set)\n",
    "    except Exception as exp:\n",
    "        print(index, \"\\n\", exp)\n",
    "\n",
    "# Function to update values in the \"types\" and \"risk\" columns based on the condition\n",
    "def update_types_risk(row):\n",
    "    if not isinstance(row['types'], str):\n",
    "        return row[\"types\"], row[\"risk\"]\n",
    "\n",
    "    if row['types'].endswith(\"risk\"):\n",
    "        return row['risk'], row['types']\n",
    "    else:\n",
    "        return row['types'], row['risk']\n",
    "\n",
    "# Apply the function to update the \"types\" and \"risk\" columns\n",
    "val['types'], val['risk'] = zip(*val.apply(update_types_risk, axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is for Java FP-Growth expanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "schema = StructType([\n",
    "    StructField(\"items\", ArrayType(StringType()), nullable=True)\n",
    "])\n",
    "A = [\n",
    "    [\"r\", \"z\", \"h\", \"k\", \"p\"],\n",
    "    [\"z\", \"y\", \"x\", \"w\", \"v\"],\n",
    "    [\"s\", \"x\", \"o\", \"n\", \"r\"],\n",
    "    [\"x\", \"z\", \"y\", \"m\", \"t\"],\n",
    "    [\"z\"],\n",
    "    [\"x\", \"z\", \"y\", \"r\", \"q\"]\n",
    "]\n",
    "rdd = spark.sparkContext.parallelize(sets_proper)\n",
    "df = spark.createDataFrame(rdd.map(lambda x: (x,)), schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(truncate=False)\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "fp = FPGrowth(itemsCol=\"items\", minSupport=0.000107, minConfidence=0.1)\n",
    "fpm=fp.fit(df)\n",
    "fpm.setPredictionCol(\"newPrediction\")\n",
    "# fpm.freqItemsets.sort(\"items\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "fp_association = fpm.associationRules.withColumn('antecedent', F.concat_ws('-', F.col(\"antecedent\").cast(\"array<string>\")))\\\n",
    "                         .withColumn('consequent', F.concat_ws('-', F.col(\"consequent\").cast(\"array<string>\")))\n",
    "new_data = spark.createDataFrame([([\"t\", \"s\"], )], [\"items\"])\n",
    "fp_association.write.csv(r\"../FP_Growth_Inference/fpres.csv\", mode = \"overwrite\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Approach on Large Matrix Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namedEntityUpper = cos_sim(data, data[:int(len(data)/20)])\n",
    "namedEntityUpper.shape\n",
    "mask = torch.gt(namedEntityUpper, 0.85)\n",
    "soCalled = namedEntityUpper * mask  # namedEntityUpper.cpu() * mask.cpu()\n",
    "soCalled.shape\n",
    "soCalled = namedEntityUpper.cpu()[mask.cpu()]\n",
    "indices = torch.nonzero(mask, as_tuple=False)\n",
    "indices.shape\n",
    "pureIdx = indices.numpy()\n",
    "conMask = pureIdx[:,0]!=pureIdx[:,1]\n",
    "pureIdx = pureIdx[conMask]\n",
    "pureIdx.shape\n",
    "keys = np.unique(pureIdx[:,0])\n",
    "clusters = {}\n",
    "for key in keys:\n",
    "    cluster = pureIdx[pureIdx[:,0]==key][:,1]\n",
    "    fetch = df.iloc[:,0].values[cluster].tolist()\n",
    "    clusters[key] = fetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@honer_solution.register\n",
    "def _(marker: str, obj: list):\n",
    "    \"\"\"\n",
    "    only solve answer that in one line. e.g\n",
    "    Sure! Based on the given sentence, here are the three categories I would assign:\n",
    "    * Risk: droughts\n",
    "    * Stakeholder: forest ecosystem, climate change\n",
    "    * Project: simulation of changes in live carbon stocks in the Amazon Basin\n",
    "    4\n",
    "    \"\"\"\n",
    "    global head_pattern\n",
    "    three_ele, index,  = obj[:-1], obj[-1],\n",
    "    extra: dict[str: list[str]] = {}\n",
    "    try:\n",
    "        three_ele = [ab_ele.split(\":\") for ab_ele in three_ele]\n",
    "        for real_time in three_ele:\n",
    "            if not real_time[1]: real_time[1] = []\n",
    "            else: real_time[1] = [re.sub(r'^\\W+|\\W+$', '', val) for val in real_time[1].split(\",\", -1)]\n",
    "        return {name_correct(real_time[0]): real_time[1] for real_time in three_ele}, extra, index\n",
    "    except Exception as e:\n",
    "        return False, e, index\n",
    "\n",
    "    # old design, only for entire text list in answer in one line\n",
    "    three_ele = [ab_ele.split(\":\") for ab_ele in three_ele]\n",
    "    return {name_correct(real_time[0]): [*(real_time[1].split(\",\", -1) if real_time[1] else [])] \\\n",
    "            for real_time in three_ele}, \\\n",
    "            extra, index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change text extraction from \"for\" to \"while\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _(marker: int, obj: list):\n",
    "    \"\"\"\n",
    "    problem 1: index may not be able always keep the number in the last line\n",
    "    problem 2: there will be extra explaination sentnece, find them out\n",
    "    \"\"\"\n",
    "    global head_pattern\n",
    "    three_ele, index, catIdx, whileCounter = obj[:-1], obj[-1], 0, 0\n",
    "    extra: dict[str: list[str]] = {}\n",
    "\n",
    "    for idx, _ in enumerate(three_ele):\n",
    "        # idx = idx - whileCounter\n",
    "        # used to extract text that only in one line\n",
    "        val, real = oneLine(three_ele[idx])\n",
    "        if isinstance(real, str): # or real>0:\n",
    "            real = [re.sub(r'^\\W+|\\W+$', '', val) for val in real.split(\",\", -1)]\n",
    "            if val not in extra.keys(): extra[val] = real\n",
    "            else: extra[val].extend(real)\n",
    "            continue\n",
    "        elif real == -1: catIdx = idx\n",
    "        \n",
    "        # used to extract text that answer in mutiple lines\n",
    "        category, counter = None, 0\n",
    "        while counter<5 and idx<len(three_ele) and not re.search(head_pattern, \" \".join(three_ele[idx].split()[:2]), re.IGNORECASE):\n",
    "            category_tuple = re.search(head_pattern, three_ele[catIdx], re.IGNORECASE) # idx - 1\n",
    "            if not category_tuple: \n",
    "                counter+=1\n",
    "                continue\n",
    "            if not category: \n",
    "                start, end = category_tuple.span()\n",
    "                if three_ele[catIdx][:3] == \"Cat\": category = three_ele[catIdx][end+1: ] # idx - 1\n",
    "                else: category = name_correct(three_ele[catIdx][start:end]) # idx - 1\n",
    "            strFlow = re.sub(r'^\\W+|\\W+$', '', three_ele.pop(idx))\n",
    "            strFlow = [re.sub(r'^\\W+|\\W+$', '', val) for val in strFlow.split(\",\", -1)]\n",
    "            whileCounter+=1\n",
    "            if category not in extra.keys(): extra[category] = strFlow\n",
    "            else: extra[category].extend(strFlow)\n",
    "            # counter+=1\n",
    "            \n",
    "    if len(extra):\n",
    "        return extra, [], index\n",
    "\n",
    "    return False, three_ele, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"lenth of entire text dataset:\", len(test_res), \"\\n\",\\\n",
    "      \"lenth of unhandled text:\", len(abnormal), \"\\n\",\\\n",
    "      \"lenth of sucessful processed text:\", len(abs_data), \"\\n\",\\\n",
    "        \"abnormal ratio:\", round(len(abnormal)/len(test_res),3))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
