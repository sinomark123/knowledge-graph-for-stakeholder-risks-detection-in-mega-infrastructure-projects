{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import *\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import sklearn\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster\n",
    "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    # print(last_hidden.shape)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(r\"Embedding_Model/gte_base\")\n",
    "# model = AutoModel.from_pretrained(r\"Embedding_Model/gte_base\")\n",
    "model: SentenceTransformer = SentenceTransformer('thenlper/gte-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val1=tokenizer.save_pretrained(r\"Embedding_Model/gte_large\")\n",
    "# val2= model.save_pretrained(r\"Embedding_Model/gte_large/\")\n",
    "# model.save(r\"Embedding_Model/gte_base_sentence\")\n",
    "\n",
    "# att= tokenizer(temp_project[0], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "# out_test = model(**att)\n",
    "# print(out_test.last_hidden_state.shape, type(out_test), \"\\n\", len(temp_project[0])\\\n",
    "#       , sum([len(val) for val in temp_project[0]]), max([len(val) for val in temp_project[0]]))\n",
    "# # print(model.config)\n",
    "# embedds = average_pool(out_test.last_hidden_state, att[\"attention_mask\"])\n",
    "# print(embedds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = pd.read_csv(r\"Generated_Result/10k.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqi22\\AppData\\Local\\Temp\\ipykernel_19784\\922194924.py:1: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'None' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data_input.fillna(\"None\", inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>risk</th>\n",
       "      <th>stakeholder</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geological CO2 sequestration</td>\n",
       "      <td>Mitigation of anthropogenic carbon dioxide emi...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>development and validation of a discrete event...</td>\n",
       "      <td>None</td>\n",
       "      <td>commercial vehicles passing through the area</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Urban renaissance project in the area of Gazi</td>\n",
       "      <td>Pollution from the industrial use of Gazi|whic...</td>\n",
       "      <td>Residents of Gazi|environmental activists|loca...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simulation of changes in live carbon stocks in...</td>\n",
       "      <td>droughts</td>\n",
       "      <td>forest ecosystem|climate change</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ecological enhancement of coastal and marine i...</td>\n",
       "      <td>degraded or reduced habitat for native species</td>\n",
       "      <td>ecosystem and habitat value|this paper present...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             project  \\\n",
       "0                       Geological CO2 sequestration   \n",
       "1  development and validation of a discrete event...   \n",
       "2      Urban renaissance project in the area of Gazi   \n",
       "3  simulation of changes in live carbon stocks in...   \n",
       "4  Ecological enhancement of coastal and marine i...   \n",
       "\n",
       "                                                risk  \\\n",
       "0  Mitigation of anthropogenic carbon dioxide emi...   \n",
       "1                                               None   \n",
       "2  Pollution from the industrial use of Gazi|whic...   \n",
       "3                                           droughts   \n",
       "4     degraded or reduced habitat for native species   \n",
       "\n",
       "                                         stakeholder  idx  \n",
       "0                                               None  0.0  \n",
       "1       commercial vehicles passing through the area  1.0  \n",
       "2  Residents of Gazi|environmental activists|loca...  2.0  \n",
       "3                    forest ecosystem|climate change  4.0  \n",
       "4  ecosystem and habitat value|this paper present...  5.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input.fillna(\"None\", inplace=True)\n",
    "data_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11667 14328 16924\n"
     ]
    }
   ],
   "source": [
    "stupid: Dict[str, List] = {}\n",
    "for col in [\"project\", \"risk\", \"stakeholder\"]:\n",
    "    temp = data_input.loc[:, col]\n",
    "    blyat = []\n",
    "    for tep_val in temp.values.tolist():\n",
    "        if tep_val[0] != tep_val[0] or tep_val==\"None\": continue\n",
    "        tep_val = tep_val.split(\"|\")\n",
    "        blyat = [*blyat, *tep_val]\n",
    "    stupid[col] = blyat\n",
    "\n",
    "# stupid_copy = {col: [val for val in data_input[col].str.split(\"|\", expand=True).stack().dropna()]\\\n",
    "#            for col in [\"Project\", \"Risk\", \"Stakeholder\"]}\n",
    "print(len(stupid[\"project\"]), len(stupid[\"risk\"]), len(stupid[\"stakeholder\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_project = [stupid[\"risk\"][val: val+5] for val in range(0, len(stupid[\"risk\"]), 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stupid[\"stakeholder\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class Node:\n",
    "  def __init__(self, name, embeddings):\n",
    "    self.name: str =name\n",
    "    self.embeddings: np.ndarray = embeddings\n",
    "\n",
    "  def __call__(self):\n",
    "    return self.embeddings\n",
    "\n",
    "def embedding_value(col, max_lim=1000, threshold=200):\n",
    "    lens = max_lim if max_lim > threshold else len(stupid[col])\n",
    "    output_project = []\n",
    "    for item in range(0, math.ceil(lens/threshold)):\n",
    "        centre = stupid[col][item*threshold:(item+1)*threshold if (item+1)*threshold<lens-1 else lens-1]\n",
    "        print(item, len(centre))\n",
    "        # Tokenize the input texts\n",
    "        res = model.encode(centre, batch_size=len(centre), convert_to_numpy=1) # return a numpy vector in threhold * embedding dim shape\n",
    "        output_project.extend([Node(*new_one) for new_one in zip(centre, [*res])])\n",
    "    return output_project # use multi-processing next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['project', 'risk', 'stakeholder', 'idx']\n"
     ]
    }
   ],
   "source": [
    "columns = data_input.columns.to_list()\n",
    "print(columns)\n",
    "# projectRes = embedding_value(col=columns[0], max_lim=1000, threshold=200)\n",
    "# len(projectRes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'risk'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import word_embedding_acc as weacc\n",
    "reload(weacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                name embedding_0 embedding_1  \\\n",
      "0  Mitigation of anthropogenic carbon dioxide emi...    0.003574   -0.003208   \n",
      "1  injection capacity and safety of the storage s...   -0.021322   -0.006011   \n",
      "2                         fluid flow in porous media   -0.000565    0.008649   \n",
      "\n",
      "  embedding_2 embedding_3 embedding_4 embedding_5 embedding_6 embedding_7  \\\n",
      "0    0.018408    0.008215    0.070227    0.022868    0.015587    0.033817   \n",
      "1   -0.011679     0.03773    0.094119    0.019343    0.034572    0.022691   \n",
      "2    0.016875    0.008861    0.057814    0.023462    0.031459     0.04278   \n",
      "\n",
      "  embedding_8  ... embedding_758 embedding_759 embedding_760 embedding_761  \\\n",
      "0   -0.020889  ...      0.041077      -0.01497     -0.035081     -0.023601   \n",
      "1   -0.031523  ...      0.004187     -0.016691      0.010008     -0.041102   \n",
      "2   -0.009724  ...      0.038016      -0.00126     -0.019946     -0.059347   \n",
      "\n",
      "  embedding_762 embedding_763 embedding_764 embedding_765 embedding_766  \\\n",
      "0      0.031124     -0.063821      0.011726     -0.003841      0.013501   \n",
      "1       0.00243     -0.000817      0.055267      0.005657      0.003692   \n",
      "2     -0.001444     -0.014403     -0.019442     -0.016936      0.005656   \n",
      "\n",
      "  embedding_767  \n",
      "0     -0.048565  \n",
      "1      0.015211  \n",
      "2      0.022867  \n",
      "\n",
      "[3 rows x 769 columns] (14327, 769)\n",
      "CPU times: total: 4min 58s\n",
      "Wall time: 22min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import concurrent.futures\n",
    "import gc\n",
    "\n",
    "counter = 0\n",
    "def main():\n",
    "    dataset = pd.DataFrame(columns=[\"name\", *[f\"embedding_{val}\" for val in range(768)]])\n",
    "    projectRes, newShape = [], 0\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        projectRes = executor.submit(embedding_value, col=columns[1], max_lim=10, threshold=200).result()\n",
    "    newShape = len(projectRes)\n",
    "    for items in range(newShape):\n",
    "        pidx: Node = projectRes[items]\n",
    "        data = [pidx.name, *pidx.embeddings]\n",
    "        dataset.loc[items, ] = pd.Series(data, index=dataset.columns)\n",
    "    return dataset\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = weacc.acc(columns, 1, stupid, model)\n",
    "    gc.collect()\n",
    "    print(dataset.head(3), dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "dataset.to_csv(r\"Generated_Result/10k_risk_embedding.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data_input.columns.to_list()\n",
    "temp = [\"risk\", \"project\"]\n",
    "\n",
    "threshold = 200\n",
    "lens = len(stupid[col])\n",
    "new_item_list = []\n",
    "for item in range(0, math.ceil(lens/threshold)):\n",
    "    new_item_list.append(stupid[col][:(item+1)*threshold] if (item+1)*threshold<lens-1 else lens-1)\n",
    "    \n",
    "for col in temp:\n",
    "    embedding_value(col=col, threshold=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beside stakeholder, rest of them shall be reloaded again\n",
    "torch.save(torch.cat(output_project, axis=0), \"Embedding_Model/gte_large_embedding/three_ouput1_risk.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_emd, atten_mask = outputs.last_hidden_state, batch_dict['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 6, 768]) torch.Size([4, 6]) torch.Size([4, 768])\n"
     ]
    }
   ],
   "source": [
    "print(full_emd.shape, atten_mask.shape, embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69.65817260742188, 88.03556060791016, 68.79690551757812]]\n"
     ]
    }
   ],
   "source": [
    "# (Optionally) normalize embeddings\n",
    "embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "scores = (embeddings[:1] @ embeddings[1:].T) * 100\n",
    "print(scores.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv(r\"Generated_Result/1k_fp.csv\", sep=';')\n",
    "d1.to_excel(r\"Generated_Result/new_split_quota.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
