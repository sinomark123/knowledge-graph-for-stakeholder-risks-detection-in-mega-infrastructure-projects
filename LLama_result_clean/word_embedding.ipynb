{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import *\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    # print(last_hidden.shape)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(r\"Embedding_Model/gte_large\")\n",
    "model = AutoModel.from_pretrained(r\"Embedding_Model/gte_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('Embedding_Model/gte_large\\\\tokenizer_config.json',\n",
       "  'Embedding_Model/gte_large\\\\special_tokens_map.json',\n",
       "  'Embedding_Model/gte_large\\\\vocab.txt',\n",
       "  'Embedding_Model/gte_large\\\\added_tokens.json',\n",
       "  'Embedding_Model/gte_large\\\\tokenizer.json'),\n",
       " None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val1=tokenizer.save_pretrained(r\"Embedding_Model/gte_large\")\n",
    "# val2= model.save_pretrained(r\"Embedding_Model/gte_large/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = pd.read_csv(r\"Generated_Result/three_output1.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stupid: Dict[str, List] = {}\n",
    "for col in [\"Project\", \"Risk\", \"Stakeholder\"]:\n",
    "    temp = data_input.loc[:, [col]]\n",
    "    blyat = []\n",
    "    for tep_val in temp.values.tolist():\n",
    "        if tep_val[0] != tep_val[0]: continue\n",
    "        tep_val = tep_val[0].split(\"| \")\n",
    "        blyat = [*blyat, *tep_val]\n",
    "    stupid[col] = blyat\n",
    "\n",
    "# stupid_copy = {col: [val for val in data_input[col].str.split(\"|\", expand=True).stack().dropna()]\\\n",
    "#            for col in [\"Project\", \"Risk\", \"Stakeholder\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_project = [stupid[\"Risk\"][val: val+5] for val in range(0, len(stupid[\"Risk\"]), 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"Stakeholder\", \"Project\"]:\n",
    "    temp_project = [stupid[col][val: val+3] for val in range(0, len(stupid[col]), 3)]\n",
    "    output_project = []\n",
    "    for ele in temp_project:\n",
    "        # Tokenize the input texts\n",
    "        batch_dict = tokenizer(ele, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "        outputs = model(**batch_dict)\n",
    "        embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "        output_project.append(embeddings)\n",
    "        torch.save(torch.cat(output_project, axis=0), f\"Embedding_Model/gte_large_embedding/three_ouput1_{col}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beside stakeholder, rest of them shall be reloaded again\n",
    "\n",
    "torch.save(torch.cat(output_project, axis=0), \"Embedding_Model/gte_large_embedding/three_ouput1_risk.pt\")\n",
    "# print(len(stupid[\"Project\"]), torch.cat(output_project, axis=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp_project=0\n",
    "# embeddings = 0\n",
    "# stupid[\"Project\"]=0\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_emd, atten_mask = outputs.last_hidden_state, batch_dict['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 6, 768]) torch.Size([4, 6]) torch.Size([4, 768])\n"
     ]
    }
   ],
   "source": [
    "print(full_emd.shape, atten_mask.shape, embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69.65817260742188, 88.03556060791016, 68.79690551757812]]\n"
     ]
    }
   ],
   "source": [
    "# (Optionally) normalize embeddings\n",
    "embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "scores = (embeddings[:1] @ embeddings[1:].T) * 100\n",
    "print(scores.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv(r\"Generated_Result/1k_fp.csv\", sep=';')\n",
    "d1.to_excel(r\"Generated_Result/new_split_quota.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
