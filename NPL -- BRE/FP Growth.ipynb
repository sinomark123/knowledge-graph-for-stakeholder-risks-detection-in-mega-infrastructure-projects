{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3681ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpgrowth_py import fpgrowth\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import spacy\n",
    "import seaborn as sns\n",
    "from spacy import displacy\n",
    "from flashtext import KeywordProcessor\n",
    "# import pyplot-express as px\n",
    "\n",
    "pathprefix = r\"D:\\Code Working Area\\Jupyter\\knowledge-graph-for-stakeholder-risks-detection-in-mega-infrastructure-projects\\ExcelData\"\n",
    "jsfile = pathprefix+\"\\\\Transactions.json\"\n",
    "\n",
    "project = pathprefix+\"\\\\Gg.csv\"\n",
    "risk = pathprefix+\"\\\\Risk_Simplified.xlsx\"\n",
    "stake = pathprefix+\"\\\\expansive.csv\"\n",
    "\n",
    "project1 = pathprefix+\"\\\\newTitle_Project.xlsx\"\n",
    "risk0 = pathprefix+\"\\\\RiskFinal.xlsx\"\n",
    "stake1 = pathprefix+\"\\\\New_StakeHolder_Abstract.xlsx\"\n",
    "\n",
    "stake2 = pathprefix+\"\\\\second_layer_stakeholder.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17bb1f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Code Working Area\\\\Jupyter\\\\knowledge-graph-for-stakeholder-risks-detection-in-mega-infrastructure-projects\\\\ExcelData\\\\second_layer_stakeholder.xlsx'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install regex\n",
    "# !pip install sapcy\n",
    "# !pip install fpgrowth_py\n",
    "# !pip install pandas\n",
    "# !pip install seaborn\n",
    "# !pip install openpyxl\n",
    "# !python -m spacy install en_core_web_sm\n",
    "stake2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4136250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqi22\\AppData\\Local\\Temp\\ipykernel_16576\\2096727506.py:1: DtypeWarning: Columns (3,7,8,12,13,18,27,28,29,30,31,38,39,40,41,42,43,44,45,50,51,53,54,59,63,64,65,67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pj = pd.read_csv(project, sep = \",\")\n"
     ]
    }
   ],
   "source": [
    "pj = pd.read_csv(project, sep = \",\")\n",
    "risk1 = pd.read_excel(risk)\n",
    "stk = pd.read_csv(stake, sep = \",\")\n",
    "\n",
    "prj = pd.read_excel(project1)\n",
    "risk2 = pd.read_excel(risk0)\n",
    "stk1 = pd.read_excel(stake1)\n",
    "stk2 = pd.read_excel(stake2)\n",
    "stk2.dropna()\n",
    "\n",
    "en = spacy.load('en_core_web_sm')\n",
    "stopwords = en.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6369d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the target text from original dataset to match\n",
    "nproject = pd.DataFrame(pj[\"Article Title\"])\n",
    "nrisk = pd.DataFrame(risk1[\"Abstract\"])\n",
    "nstack = pd.DataFrame(stk[\"Abstract\"])\n",
    "\n",
    "nrisk.Abstract = nrisk.Abstract.fillna(\"No Context\")\n",
    "\n",
    "stk1.name = stk1.name.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "659980c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_dashes(droped: int)->pd.DataFrame:\n",
    "    dashes = pd.read_excel(pathprefix+\"\\\\adjustment.xlsx\")\n",
    "    dashes = dashes[dashes.frequency > droped].Words.to_list()\n",
    "    return set(dashes)\n",
    "\n",
    "stopwords |= reload_dashes(2)\n",
    "# filout = pd.read_excel(r\"D:\\Code Working Area\\Python\\knowledge-graph-for-stakeholder-risks-detection-in-mega-infrastructure-projects\\ExcelData\\filtered.xlsx\")\n",
    "# stopwords |= set(filout.name.to_list())\n",
    "stopwords |= set([str(num) for num in range(1,100)])\n",
    "\n",
    "# manually add the words to the stopwords\n",
    "possiblew = {\"connections\", \"efficacy\", \"life\", \"This\"}\n",
    "stopwords |= possiblew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "efc75e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split the stakeholder org words and count the frequency\n",
    "# arr1 = stk1.name.str.split(\" \").explode()\n",
    "# fre = pd.DataFrame(data=arr1.value_counts())\n",
    "# fre.reset_index(inplace = True)\n",
    "# fre = fre.rename(columns = {\"name\": \"frequency\", \"index\": \"name\"})\n",
    "# filtered = fre[fre.name.apply(lambda x: x not in stopwords)].reset_index(drop = True)\n",
    "# filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8bc8fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pick up the ORG whose frequency larger than 30\n",
    "# fre = pd.read_csv(r\"D:\\Code Working Area\\Python\\knowledge-graph-for-stakeholder-risks-detection-in-mega-infrastructure-projects\\ExcelData\\Examples\\ORG_frequency.csv\")\n",
    "# chosenone = fre[fre.frequency >= 30]\n",
    "# chosenone = chosenone[chosenone.name.apply(lambda x: x not in stopwords)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "201b207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combination(keyw: str, extracted: list):\n",
    "    extracted = list(set(extracted))\n",
    "    temp = []\n",
    "    for val in range(0, len(extracted)):\n",
    "        if re.sub(\"\\W\", \"\", extracted[val]) not in stopwords: temp.append(extracted[val])\n",
    "    del extracted\n",
    "    return [ele+\" \"+ keyw for ele in temp] if len(temp) else []\n",
    "\n",
    "def regex_match(keyword: str, args:str):\n",
    "    temp = args\n",
    "    lookbehind = rf\"(?<=\\b{keyword})(\\W\\W?\\w+)\"\n",
    "    lookforward = rf\"(\\w+\\W\\W?)(?=\\b{keyword}\\s)\"\n",
    "    return combination(keyword, re.findall(lookforward, temp)) + combination(keyword, re.findall(lookbehind, temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7de324e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pre-process of matching, but only apply for risk keyword abstraction\n",
    "def reduction(args: str, val: str):\n",
    "    args = str(args)\n",
    "    for item in args:\n",
    "        if item in [\"(\", \")\", \"+\"]: args = args.replace(item, \" \")\n",
    "    try:\n",
    "        return re.search(rf\"\\b{args}\\b\", val) != None\n",
    "    except Exception:\n",
    "        print(\"the currently word is: %s\", args, flags = re.IGNORECASE)\n",
    "    \n",
    "def dummy_project(args: pd.Series, val: str):\n",
    "    ags = str(args)\n",
    "    return val.find(args) != -1\n",
    "\n",
    "def match_attributes(args: str):\n",
    "    \"\"\"args are the value from nrisk.Abstract\"\"\"\n",
    "    res = prj[\"Article Title\"].apply(dummy_project, args = (args, ))\n",
    "    casualty = prj[\"Article Title\"][res == True].to_list()\n",
    "    res = risk2[\"Abstract\"].apply(reduction, args= (args, ))\n",
    "    casualty = [*casualty, *risk2.Abstract[res==True].to_list()]\n",
    "    # convert list into new rows (attention here the res is in pd.Series type not pd.DataFrame)\n",
    "    res=stk2[\"stk\"].apply(reduction, args=(args,))\n",
    "    res=stk2.stk[res==True]\n",
    "    casualty = [*casualty, *res.to_list()]\n",
    "    return casualty\n",
    "\n",
    "def write_json(new_data, filepath=jsfile):\n",
    "    with open(filepath,'r+') as file:\n",
    "          # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        # Join new_data with file_data inside emp_details\n",
    "        file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file, indent = 4)\n",
    "\n",
    "# first run the first 500 lines and find out the frequency, delete the words whose frequency larger than 5\n",
    "def extraction(rnum: tuple = (0, 500)):\n",
    "    for value in nrisk.iloc[rnum[0]:rnum[1]].itertuples(): \n",
    "        if type(value.Abstract) is int or type(value.Abstract) is float: \n",
    "            print(value)\n",
    "            continue\n",
    "        write_json(match_attributes(value.Abstract))\n",
    "#         match_attributes(value.Abstract)\n",
    "    return\n",
    "\n",
    "interval: list=[(0, 50), (150, 400), (1000, 1500)]\n",
    "\n",
    "for items in interval:\n",
    "    extraction(items)\n",
    "# nrisk.value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71fa9d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>stk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Stakeholder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>the Stakeholder Circle Methodology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>PPM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20478</th>\n",
       "      <td>20480.0</td>\n",
       "      <td>the Sustainable Human Resource Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20479</th>\n",
       "      <td>20481.0</td>\n",
       "      <td>OLCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20480</th>\n",
       "      <td>20482.0</td>\n",
       "      <td>The New York Times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20481</th>\n",
       "      <td>20483.0</td>\n",
       "      <td>Bi-Oceanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20482</th>\n",
       "      <td>20484.0</td>\n",
       "      <td>SMBs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20483 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0                                          1\n",
       "0          NaN                                        stk\n",
       "1          0.0                                Stakeholder\n",
       "2          1.0         the Stakeholder Circle Methodology\n",
       "3          2.0                                        PPM\n",
       "4          3.0                     Research & Development\n",
       "...        ...                                        ...\n",
       "20478  20480.0  the Sustainable Human Resource Management\n",
       "20479  20481.0                                       OLCA\n",
       "20480  20482.0                         The New York Times\n",
       "20481  20483.0                                 Bi-Oceanic\n",
       "20482  20484.0                                       SMBs\n",
       "\n",
       "[20483 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stk2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05f073d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process on the stake keyword -- clean\n",
    "files: list = []\n",
    "with open(jsfile, \"r\") as file:\n",
    "    files = json.load(file)\n",
    "# files = pd.DataFrame({\"Words\": files})\n",
    "# files[\"expansion\"] = files.explode(\"Words\").reset_index(drop = True)\n",
    "\n",
    "# # sns.histplot(data = files, x = \"Words\", kde = True) # quiet useless\n",
    "# dashes = pd.DataFrame(files.value_counts()).reset_index(level = 0)\n",
    "# dashes.columns = [\"words\", \"frequency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48a2902c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['uses risk', 'accident risk', 'operation risk', 'TAR'],\n",
       " ['safety risk'],\n",
       " ['early risk', 'aggregate risk'],\n",
       " ['different risk', 'Weibull'],\n",
       " ['construction project', 'struction project', 'political risk', 'CFA'],\n",
       " ['quantified risk',\n",
       "  'proposed risk',\n",
       "  'drought risk',\n",
       "  'annual risk',\n",
       "  'fed',\n",
       "  'CC',\n",
       "  'Correlation',\n",
       "  'Curve']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=[x for x in files if x]\n",
    "files[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7d8c8eaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# files.to_csv(r\"D:\\Code Working Area\\Python\\knowledge-graph-for-stakeholder-risks-detection-in-mega-infrastructure-projects\\ExcelData\\Examples\\NewExample.csv\", index = False)\n",
    "# auxilary function, used to filter out stakeholder\n",
    "stk1 = pd.read_excel(stake1)\n",
    "def spacy_render(args: str):\n",
    "    doc = nlp(args)\n",
    "    displacy.render(doc, style = \"ent\")\n",
    "\n",
    "def quardoric(args: str):\n",
    "    doc=nlp(args)\n",
    "    return [tect.text for tect in doc.ents if tect.label_ == \"ORG\"]\n",
    "stk1.name = stk1.name.astype(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33010647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this step, we are going to handle on fp_growth\n",
    "# fpgrowth minSupRatio should not over than 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7642dd57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa01eb00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7e9ddac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "948f5d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5215caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d05b0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e2a22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
