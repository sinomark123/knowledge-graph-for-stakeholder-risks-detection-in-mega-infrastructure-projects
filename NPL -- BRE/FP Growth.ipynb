{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3681ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pandas\n",
    "from fpgrowth_py import fpgrowth\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import spacy\n",
    "import seaborn as sns\n",
    "from spacy import displacy\n",
    "from flashtext import KeywordProcessor\n",
    "import ahocorasick\n",
    "import nltk\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from enum import Enum\n",
    "\n",
    "pathprefix = r\"D:\\Code Working Area\\Jupyter\\knowledge-graph-for-stakeholder-risks-detection-in-mega-infrastructure-projects\\ExcelData\"\n",
    "jsfile = pathprefix+\"\\\\Transactions.json\"\n",
    "\n",
    "project_sor = pathprefix+\"\\\\Source\\\\project.csv\"\n",
    "risk_sor = pathprefix+\"\\\\Source\\\\risk.xlsx\"\n",
    "stake_sor = pathprefix+\"\\\\Source\\\\stakeholder.csv\"\n",
    "\n",
    "project_key = pathprefix+\"\\\\project_keyword\\\\Project_keyword.xlsx\"\n",
    "risk_key = pathprefix+\"\\\\risk_keyword\\\\Risk_keyword.xlsx\"\n",
    "stake_key = pathprefix+\"\\\\stakeholder_keyword\\\\third_layer_iteration_one_stakeholder.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb1f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4136250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqi22\\AppData\\Local\\Temp\\ipykernel_16028\\1613656925.py:1: DtypeWarning: Columns (3,7,8,12,13,18,27,28,29,30,31,38,39,40,41,42,43,44,45,50,51,53,54,59,63,64,65,67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pj = pd.read_csv(project, sep = \",\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                        Abstract\n0                                    Stakeholder\n1             the Stakeholder Circle Methodology\n2                                            PPM\n3                         Research & Development\n4                                           VCSA\n...                                          ...\n20477  the Sustainable Human Resource Management\n20478                                       OLCA\n20479                         The New York Times\n20480                                 Bi-Oceanic\n20481                                       SMBs\n\n[20482 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Abstract</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Stakeholder</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the Stakeholder Circle Methodology</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PPM</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Research &amp; Development</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>VCSA</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20477</th>\n      <td>the Sustainable Human Resource Management</td>\n    </tr>\n    <tr>\n      <th>20478</th>\n      <td>OLCA</td>\n    </tr>\n    <tr>\n      <th>20479</th>\n      <td>The New York Times</td>\n    </tr>\n    <tr>\n      <th>20480</th>\n      <td>Bi-Oceanic</td>\n    </tr>\n    <tr>\n      <th>20481</th>\n      <td>SMBs</td>\n    </tr>\n  </tbody>\n</table>\n<p>20482 rows Ã— 1 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prj_sor = pd.read_csv(project_sor, sep = \",\")\n",
    "risk_sor = pd.read_excel(risk_sor)\n",
    "stk_sor = pd.read_csv(stake_sor, sep = \",\")\n",
    "\n",
    "prj_key = pd.read_excel(project_key, index_col=None)\n",
    "risk_key = pd.read_excel(risk_key, index_col=None)\n",
    "stk_key = pd.read_excel(stake_key, index_col=None)\n",
    "stk_key.dropna(inplace=True)\n",
    "\n",
    "en = spacy.load('en_core_web_sm')\n",
    "stopwords = en.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6369d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the target text from original dataset to match\n",
    "project = pd.DataFrame(prj_sor[\"Article Title\"])\n",
    "risk = pd.DataFrame(risk_sor[\"Abstract\"])\n",
    "stake = pd.DataFrame(stk_sor[\"Abstract\"])\n",
    "\n",
    "risk.dropna(inplace=True, how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm') # disable=[\"attribute_ruler\"]\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "nlp.pipe_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "659980c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_dashes(droped: int)->pd.DataFrame:\n",
    "    dashes = pd.read_excel(pathprefix+\"\\\\adjustment.xlsx\")\n",
    "    dashes = dashes[dashes.frequency > droped].Words.to_list()\n",
    "    return set(dashes)\n",
    "\n",
    "stopwords |= reload_dashes(2)\n",
    "# filout = pd.read_excel(r\"D:\\Code Working Area\\Python\\knowledge-graph-for-stakeholder-risks-detection-in-mega-infrastructure-projects\\ExcelData\\filtered.xlsx\")\n",
    "# stopwords |= set(filout.name.to_list())\n",
    "stopwords |= set([str(num) for num in range(1,100)])\n",
    "\n",
    "# manually add the words to the stopwords\n",
    "possiblew = {\"connections\", \"efficacy\", \"life\", \"This\"}\n",
    "stopwords |= possiblew\n",
    "\n",
    "for word in stopwords:\n",
    "    nlp.vocab[word].is_stop=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ec411d",
   "metadata": {},
   "source": [
    "# # split the stakeholder org words and count the frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efc75e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr1 = stk1.name.str.split(\" \").explode()\n",
    "# fre = pd.DataFrame(data=arr1.value_counts())\n",
    "# fre.reset_index(inplace = True)\n",
    "# fre = fre.rename(columns = {\"name\": \"frequency\", \"index\": \"name\"})\n",
    "# filtered = fre[fre.name.apply(lambda x: x not in stopwords)].reset_index(drop = True)\n",
    "# filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def clean_text(headline):\n",
    "    le=WordNetLemmatizer()\n",
    "    word_tokens=word_tokenize(headline)\n",
    "    tokens=[le.lemmatize(w) for w in word_tokens if w not in stopwords and len(w)>3]\n",
    "    cleaned_text=\" \".join(tokens)\n",
    "    return cleaned_text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "stk.Abstract=stk.Abstract.str.lower()\n",
    "# stk_lem=stk.Abstract.apply(clean_text).to_frame()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "'this is an example of how a spacy model can be used'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"this is an example of how a spacy model can be used\"\n",
    "# texts = [\n",
    "#     \"Net income was $9.4 million compared to the prior year of $2.7 million.\",\n",
    "#     \"Revenue exceeded twelve billion dollars, with a loss of $1b.\",\n",
    "# ]\n",
    "#\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# for doc in nlp.pipe(texts, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]):\n",
    "#     # Do something with the doc here\n",
    "#     print([(ent.text, ent.label_) for ent in doc.ents])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# self-customerd function\n",
    "from spacy.language import Language\n",
    "@Language.component(\"info_integration\")\n",
    "def info_integration(doc):\n",
    "    ..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def spacy_org(data):\n",
    "    vals=nlp(data)\n",
    "    # tags, ner = zip(*[(val.pos_, val.ents.label_) for val in vals if val.ents.label_ == \"ORG\"])\n",
    "    ner=[val.text for val in vals.ents if val.label_==\"ORG\"]\n",
    "    return ner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# stk.Abstract[0:100].apply(spacy_org)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# stk.loc[:, [\"tag\", \"ner\"]]=stk.Abstract.apply(lambda x: pd.Series(spacy_org(x)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LangChain ask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"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\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm=OpenAI(temperature=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "order=\" \".join(stk.loc[0:15,:].Abstract)\n",
    "text=f\"please extract out organization within this word '{stk.Abstract[1]}'\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Organization: Bank Sector\n"
     ]
    }
   ],
   "source": [
    "print(llm(text))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "\"stakeholder analysis is nowadays considered as an important part of management of all institutions. for all organisations it is necessary to analysed in detail all individuals or groups that can affect or are affected by the organisations' activities. this article deals with the detailed stakeholder analysis and identification in the bank sector. in the first part of this article there are generally defined stakeholders and the basis of stakeholder approach. the second part focuses on results of the author's pilot research of stakeholders in bank sector. the analysis of stakeholders is carried out on the basis of stakeholder circle methodology. the emphasis is on the identification and prioritisation of key stakeholders of bank institutions. the main objective of this article is verification of application possibilities of the stakeholder analysis and the stakeholder circle methodology in the bank sector and detail identification and prioritisation of key stakeholder groups of bank institutions.\""
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stk.Abstract[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('O')"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stk.Abstract.dtype"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "798bf1b3",
   "metadata": {},
   "source": [
    "## pick up the ORG whose frequency larger than 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8bc8fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fre = pd.read_csv(r\"D:\\Code Working Area\\Python\\knowledge-graph-for-stakeholder-risks-detection-in-mega-infrastructure-projects\\ExcelData\\Examples\\ORG_frequency.csv\")\n",
    "# chosenone = fre[fre.frequency >= 30]\n",
    "# chosenone = chosenone[chosenone.name.apply(lambda x: x not in stopwords)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "201b207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combination(keyw: str, extracted: list):\n",
    "    extracted = list(set(extracted))\n",
    "    temp = []\n",
    "    for val in range(0, len(extracted)):\n",
    "        if re.sub(\"\\W\", \"\", extracted[val]) not in stopwords: temp.append(extracted[val])\n",
    "    del extracted\n",
    "    return [ele+\" \"+ keyw for ele in temp] if len(temp) else []\n",
    "\n",
    "def regex_match(keyword: str, args:str):\n",
    "    temp = args\n",
    "    lookbehind = rf\"(?<=\\b{keyword})(\\W\\W?\\w+)\"\n",
    "    lookforward = rf\"(\\w+\\W\\W?)(?=\\b{keyword}\\s)\"\n",
    "    return combination(keyword, re.findall(lookforward, temp)) + combination(keyword, re.findall(lookbehind, temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7de324e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pre-process of matching, but only apply for risk keyword abstraction\n",
    "def reduction(args: str, val: str):\n",
    "    args = str(args)\n",
    "    for item in args:\n",
    "        if item in [\"(\", \")\", \"+\"]: args = args.replace(item, \" \")\n",
    "    try:\n",
    "        return re.search(rf\"\\b{args}\\b\", val) != None\n",
    "    except Exception:\n",
    "        print(\"the currently word is: %s\", args, flags = re.IGNORECASE)\n",
    "    \n",
    "def dummy_project(args: pd.Series, val: str):\n",
    "    ags = str(args)\n",
    "    return val.find(args) != -1\n",
    "\n",
    "def match_attributes(args: str):\n",
    "    \"\"\"args are the value from nrisk.Abstract\"\"\"\n",
    "    res = prj[\"Article Title\"].apply(dummy_project, args = (args, ))\n",
    "    casualty = prj[\"Article Title\"][res == True].to_list()\n",
    "    res = risk2[\"Abstract\"].apply(reduction, args= (args, ))\n",
    "    casualty = [*casualty, *risk2.Abstract[res==True].to_list()]\n",
    "    # convert list into new rows (attention here the res is in pd.Series type not pd.DataFrame)\n",
    "    res=stk2[\"stk\"].apply(reduction, args=(args,))\n",
    "    res=stk2.stk[res==True]\n",
    "    casualty = [*casualty, *res.to_list()]\n",
    "    return casualty\n",
    "\n",
    "def write_json(new_data, filepath=jsfile):\n",
    "    with open(filepath,'r+') as file:\n",
    "          # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        # Join new_data with file_data inside emp_details\n",
    "        file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file, indent = 4)\n",
    "\n",
    "# first run the first 500 lines and find out the frequency, delete the words whose frequency larger than 5\n",
    "def extraction(rnum: tuple = (0, 500)):\n",
    "    for value in nrisk.iloc[rnum[0]:rnum[1]].itertuples(): \n",
    "        if type(value.Abstract) is int or type(value.Abstract) is float: \n",
    "            print(value)\n",
    "            continue\n",
    "        write_json(match_attributes(value.Abstract))\n",
    "#         match_attributes(value.Abstract)\n",
    "    return\n",
    "\n",
    "interval: list=[(0, 50), (150, 400), (1000, 1500)]\n",
    "\n",
    "for items in interval:\n",
    "    extraction(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7bc8c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stakeholder salience has proven an elusive mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stakeholder analysis is nowadays considered as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Corporate stakeholder culture is a new study f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>According to research, stakeholder disappointm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Understanding stakeholder dynamics and their i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48336</th>\n",
       "      <td>48336</td>\n",
       "      <td>Purpose - The purpose of this paper is to expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48337</th>\n",
       "      <td>48337</td>\n",
       "      <td>Globally, banks are entering a new era. Settin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48338</th>\n",
       "      <td>48338</td>\n",
       "      <td>There has been an increased interest in utiliz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48339</th>\n",
       "      <td>48339</td>\n",
       "      <td>The corporation has been the object of scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48340</th>\n",
       "      <td>48340</td>\n",
       "      <td>Some ecological economists have advocated part...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48341 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                           Abstract\n",
       "0               0  Stakeholder salience has proven an elusive mea...\n",
       "1               1  Stakeholder analysis is nowadays considered as...\n",
       "2               2  Corporate stakeholder culture is a new study f...\n",
       "3               3  According to research, stakeholder disappointm...\n",
       "4               4  Understanding stakeholder dynamics and their i...\n",
       "...           ...                                                ...\n",
       "48336       48336  Purpose - The purpose of this paper is to expl...\n",
       "48337       48337  Globally, banks are entering a new era. Settin...\n",
       "48338       48338  There has been an increased interest in utiliz...\n",
       "48339       48339  The corporation has been the object of scienti...\n",
       "48340       48340  Some ecological economists have advocated part...\n",
       "\n",
       "[48341 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "385442a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform not that good\n",
    "# from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "# from transformers import pipeline\n",
    "#\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "# model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "#\n",
    "# nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "stk.loc[:, \"Abstract\"]=stk.Abstract.str.lower()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "\"stakeholder analysis is nowadays considered as an important part of management of all institutions. for all organisations it is necessary to analysed in detail all individuals or groups that can affect or are affected by the organisations' activities. this article deals with the detailed stakeholder analysis and identification in the bank sector. in the first part of this article there are generally defined stakeholders and the basis of stakeholder approach. the second part focuses on results of the author's pilot research of stakeholders in bank sector. the analysis of stakeholders is carried out on the basis of stakeholder circle methodology. the emphasis is on the identification and prioritisation of key stakeholders of bank institutions. the main objective of this article is verification of application possibilities of the stakeholder analysis and the stakeholder circle methodology in the bank sector and detail identification and prioritisation of key stakeholder groups of bank institutions.\""
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stk.Abstract[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71fa9d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec={'ner': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'pos': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'tokens': TensorSpec(shape=(None,), dtype=tf.string, name=None)}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "data=tfds.load(\"conll2002\")\n",
    "ds_train, info, ds_test=data[\"train\"], data[\"dev\"], data[\"test\"]\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "715677ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "physic_devices=tf.config.list_physical_devices(\"GPU\")\n",
    "physic_devices\n",
    "# tf.config.experimental.set_memory_growth(physic_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1cac1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05f073d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process on the stake keyword -- clean\n",
    "files: list = []\n",
    "with open(jsfile, \"r\") as file:\n",
    "    files = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48a2902c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['uses risk', 'accident risk', 'operation risk', 'TAR'],\n",
       " ['safety risk'],\n",
       " ['early risk', 'aggregate risk'],\n",
       " ['different risk', 'Weibull'],\n",
       " ['construction project', 'struction project', 'political risk', 'CFA'],\n",
       " ['quantified risk',\n",
       "  'proposed risk',\n",
       "  'drought risk',\n",
       "  'annual risk',\n",
       "  'fed',\n",
       "  'CC',\n",
       "  'Correlation',\n",
       "  'Curve']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7d8c8eaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# files.to_csv(r\"D:\\Code Working Area\\Python\\knowledge-graph-for-stakeholder-risks-detection-in-mega-infrastructure-projects\\ExcelData\\Examples\\NewExample.csv\", index = False)\n",
    "# auxilary function, used to filter out stakeholder\n",
    "stk1 = pd.read_excel(stake1)\n",
    "def spacy_render(args: str):\n",
    "    doc = nlp(args)\n",
    "    displacy.render(doc, style = \"ent\")\n",
    "\n",
    "def quardoric(args: str):\n",
    "    doc=nlp(args)\n",
    "    return [tect.text for tect in doc.ents if tect.label_ == \"ORG\"]\n",
    "stk1.name = stk1.name.astype(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33010647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this step, we are going to handle on fp_growth\n",
    "# fpgrowth minSupRatio should not over than 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7642dd57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa01eb00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7e9ddac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "948f5d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5215caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d05b0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e2a22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
